`Date`: 4 Dec 22 Session No. 04

`Topic`: Decision Tree and Random Forest

## Notes
- **logistic regression**
  - Logistic regression is basically a supervised classification algorithm
  - It is used to predict a binary outcome based on a set of independent variables
  
   <img src="https://miro.medium.com/max/2312/1*iKo3KI4kqkZ47W7pmmH4cw.png" width="300">
   
- **Decision Tree**
  - A decision tree is a non-parametric supervised learning algorithm, which is utilized for both classification and regression tasks
  - A tree can be “learned” by splitting the source set into subsets based on an attribute value test
  - `Decision tree can leads to Over fitting`
  
  <img src="https://static.javatpoint.com/tutorial/machine-learning/images/decision-tree-classification-algorithm.png" width="370">
     
- **Entropy**
  - Entropy measures the degree of randomness in data processed in machine learning. It determines how a decision tree chooses to split data
  
      <img src="https://static.javatpoint.com/tutorial/machine-learning/images/entropy-in-machine-learning3.png" width="450">

  - [Entropy in Machine Learning](https://www.javatpoint.com/entropy-in-machine-learning#:~:text=Entropy%20is%20defined%20as%20the%20randomness%20or%20measuring,measures%20the%20unpredictability%20or%20impurity%20in%20the%20system.)    
  
- **Gini Impurity**
  - Gini impurity measures how often a randomly chosen example would be incorrectly labeled if it was randomly labeled according to the label distribution
  - `Can be used as an alternative to entropy for selecting attributes`
  
- **Random forest**
  - Random forest is a commonly-used machine learning algorithm , which combines the output of multiple decision trees to reach a single result 
  
     <img src="https://res.cloudinary.com/springboard-images/image/upload/q_auto,f_auto,fl_lossy/wordpress-india/2020/07/Screenshot-2020-07-03-at-5.14.59-PM.png" width="380">
     
## Tasks


  
      


  
  
  
  
